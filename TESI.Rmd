---
title: "Modellazione dei Sondaggi Elettorali con Modelli State-Space"
author: "Rabuzzi Giacomo"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_depth: 2
    number_sections: true
    theme: united
    highlight: tango
runtime: shiny
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(tidyverse)
library(KFAS)
library(lubridate)
library(Matrix)
library(readxl)
library(ggrepel)
```



# Introduzione
L'obiettivo di questo documento è analizzare i sondaggi elettorali italiani tramite modelli a stati nello spazio, che ci permettono di:

* stimare l'evoluzione del consenso nel tempo;
* valutare la precisione (varianza) delle rilevazioni dei diversi istituti;
* stimare il bias sistematico degli istituti (effetto "house");
* confrontare modelli gaussiani e binomiali.
  
## Perché i modelli a stati?
I modelli a stati sono ideali per dati temporali rumorosi come i sondaggi. Permettono di scomporre una serie osservata $$y_t$$ in:
$$
y_t = \mu_t + \varepsilon_t,\quad \varepsilon_t \sim \mathcal{N}(0, H_t)
$$
Dove:

- $\mu_t$ è una variabile latente (trend del consenso);
- $\varepsilon_t$ è il rumore di misura.

Il trend latente può seguire, ad esempio, un random walk:
$$
\mu_t = \mu_{t-1} + \eta_t, \quad \eta_t \sim \mathcal{N}(0, Q_t)
$$

# Caricamento dei dati
Selezioniamo solo gli istituti per cui sono disponibile un sufficiente numero di sondaggi (i primi 16):
```{r}
dt <- read.csv2("Sondaggi_2024-04-30.csv")
dt$Percentuale <- as.numeric(dt$Percentuale)
dt$Data <- as.Date(dt$Data, format = "%d/%m/%Y")

nomi_istituti <- names(sort(table(dt$Istituto), decreasing = TRUE)[1:16])
```


# Modello con Varianza Libera (free_var_mod)
Questo modello stima la varianza specifica di ogni istituto , assumendo che il trend sia comune, ma la precisione delle rilevazioni vari in base al campione:

$$
y_{j,t} = \mu_t + \varepsilon_{j,t}, \quad \varepsilon_{j,t} \sim \mathcal{N}\left(0, \frac{\sigma_j^2}{n_{j,t}}\right)
$$

Dove:

- $y_{j,t}$: percentuale stimata dall'istituto $j$ al tempo $t$  
- $\mu_t$: trend comune (latente)  
- $n_{j,t}$: dimensione campionaria del sondaggio dell’istituto $j$ al tempo $t$  
- $\sigma_j^2$: varianza specifica dell’istituto $j$

```{r}
free_var_mod <- function(par,co) {
  library(tidyverse)
  library(KFAS)
  
  dt_filtro <- subset(dt, Istituto %in% nomi_istituti)
  
  dt_filtro %>%
    filter(Partito == par) %>%
    select(-Partito, -Campione) %>%
    pivot_wider(names_from = Istituto,
                values_from = Percentuale,
                values_fill = NA,
                values_fn = mean) %>%
    arrange(Data) -> dt_party
  
  dates <- tibble(Data = seq(min(dt$Data), max(dt$Data), "day"))
  dt_party <- dates %>% left_join(dt_party, by = "Data")
  
  dt_filtro %>%
    filter(Partito == par) %>%
    select(-Partito, -Percentuale) %>%
    pivot_wider(names_from = Istituto,
                values_from = Campione,
                values_fill = NA,
                values_fn = mean) %>%
    arrange(Data) -> dt_samples
  
  dt_samples <- dates %>% left_join(dt_samples, by = "Data")
  dt_samples[is.na(dt_samples)] <- min(dt_samples[, -1], na.rm = TRUE)
  
  Y <- as.matrix(dt_party[,-1])
  X <- as.matrix(dt_samples[,-1])
  
  p <- ncol(Y)
  n <- nrow(Y)
  
  mZ <- matrix(1, p, 1)
  mH <- array(0, c(p, p, n))
  mT <- matrix(1)
  mQ <- matrix(NA_real_, 1, 1)
  mR <- matrix(1)
  va1 <- matrix(20)
  mP1 <- matrix(56.25)
  mP1inf <- matrix(0)
  
  mod <- SSModel(Y ~ 0 + SSMcustom(mZ, mT, mR, mQ, va1, mP1, mP1inf, state_names = "mu"),
                 H = mH)
  
  updt <- function(pars, model, samples) {
    model$Q[1, 1, 1] <- exp(pars[1])
    var_eps <- exp(pars[-1])
    for (t in 1:nrow(samples)) {
      diag(model$H[,,t]) <- var_eps / samples[t, ]
    }
    model
  }
  
  fit <- fitSSM(model = mod,
                inits = log(c(var_eta = 0.1, var_eps = rep(2000, p))),
                updatefn = updt,
                update_args = list(samples = X),
                hessian = TRUE, method = 'BFGS')
  
  kfs <- KFS(fit$model, filtering = "state", smoothing = "state")
  
  dt_party_trend <- tibble(Data = dt_party$Data,
                           Trend = kfs$alphahat[, 1])
  
  g1 <- dt_filtro %>%
    filter(Partito == par) %>%
    ggplot(aes(x = Data, y = Percentuale)) +
    geom_point(color = co, alpha = 0.2) +
    geom_line(aes(x = Data, y = Trend), data = dt_party_trend, linewidth = 1) +
    ggtitle(paste("Intenzioni di voto per", par)) +
    theme_minimal(base_size = 13)
  
  param_estimates <- fit$optim.out$par
  vcov_matrix <- solve(fit$optim.out$hessian)
  std_errors <- sqrt(diag(vcov_matrix))
  z_value <- qnorm(0.975)
  
  ci_lower <- exp(param_estimates - z_value * std_errors)[-1]
  ci_upper <- exp(param_estimates + z_value * std_errors)[-1]
  
  confidence_intervals <- data.frame(
    Istituto = colnames(Y),
    Varianza = exp(param_estimates[-1]),
    Lower95 = ci_lower,
    Upper95 = ci_upper
  )
  
  g2 <- confidence_intervals %>%
    mutate(Istituto = fct_reorder(Istituto, Varianza)) %>%
    ggplot(aes(x = Istituto, y = Varianza)) +
    geom_point(size = 2) +
    geom_errorbar(aes(ymin = Lower95, ymax = Upper95), width = .25) +
    coord_flip() +
    labs(title = paste("Varianze specifiche degli istituti –", par),
         x = "Istituto",
         y = expression(hat(sigma)^2)) +
    theme_minimal(base_size = 13)
  
  return(list(
    grafico_trend = g1,
    grafico_varianze = g2,
    intervalli_varianza = confidence_intervals,
    trend_temporale = dt_party_trend
  ))
}
```

## Calcolo degli Intervalli di Confidenza sulle Varianze

Le varianze specifiche $\sigma_j^2$ sono stimate tramite massima verosimiglianza, e riportate in scala logaritmica per garantire positività. L’intervallo di confidenza al 95% per ciascuna varianza è calcolato utilizzando la matrice di varianza-covarianza ottenuta dall'inverso dell'hessiano numerico al punto ottimo:

$$
\hat{\sigma}_j^2 = \exp(\hat{\theta}_j), \quad IC_{95\%} = \left[\exp(\hat{\theta}_j - z_{0.975} \cdot SE_j), \; \exp(\hat{\theta}_j + z_{0.975} \cdot SE_j)\right]
$$

Dove:

- $\hat{\theta}_j$ è la stima log-trasformata della varianza,
- $SE_j$ è l’errore standard di $\hat{\theta}_j$,
- $z_{0.975} \approx 1.96$ è il quantile standard della normale.

La log-trasformazione garantisce che le varianze restino positive anche nei bordi dell'intervallo.

# Modello con Bias Fisso (bias_mod)
Nel modello con bias fisso, ogni osservazione $y_{j,t}$ è modellata come:

$$
y_{j,t} = \mu_t + \delta_j + \varepsilon_{j,t}, \quad \varepsilon_{j,t} \sim \mathcal{N}\left(0, \frac{\sigma^2}{n_{j,t}}\right)
$$

Dove:

- $\mu_t$ è il supporto latente medio del partito al tempo $t$;
- $\delta_j$ è il bias sistematico dell’istituto $j$;
- $n_{j,t}$ è la dimensione campionaria del sondaggio;
- $\varepsilon_{j,t}$ è l’errore statistico.

Il modello può essere riscritto come un sistema dinamico nello spazio degli stati.

$$
y_t = Z \alpha_t + \varepsilon_t
$$

Dove:

- $y_t$ è un vettore di osservazioni al tempo $t$ (una per ogni istituto);
- $\alpha_t = (\mu_t, \delta_1, \delta_2, \dots, \delta_{p-1})^\top$ è il vettore degli stati latenti;
- $Z$ è la matrice di design di dimensione $p \times p$.

Poiché imponiamo il vincolo di identificazione:

$$
\sum_j \delta_j = 0
$$

la matrice $Z$ viene costruita così:

- Una prima colonna di 1 (per $\mu_t$);
- Una matrice identità $(p-1)\times(p-1)$ per i primi $p-1$ istituti;
- L'ultimo istituto viene rappresentato come il negativo della somma dei precedenti bias:

$$
\delta_p = -\sum_{j=1}^{p-1} \delta_j
$$

Quindi la matrice $Z$ avrà la seguente struttura (schematica):

$$
Z =
\begin{bmatrix}
1 & 1 & 0 & \cdots & 0 \\
1 & 0 & 1 & \cdots & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
1 & 0 & 0 & \cdots & 1 \\
1 & -1 & -1 & \cdots & -1 \\
\end{bmatrix}
$$

L’unico stato dinamico è $\mu_t$, che evolve come un random walk:

$$
\mu_t = \mu_{t-1} + \eta_t, \quad \eta_t \sim \mathcal{N}(0, Q)
$$

Mentre i bias $\delta_j$ sono fissi nel tempo, ovvero:

$$
\delta_j(t) = \delta_j(t-1)
$$

Questo si ottiene impostando:

- matrice di transizione $T = I$ (identità);
- matrice $R$ con solo la prima riga diversa da zero, in modo che solo $\mu_t$ sia soggetto a evoluzione stocastica.

```{r}
bias_mod <- function(par,co) {
  library(tidyverse)
  library(KFAS)
  library(Matrix)
  library(readxl)
  library(lubridate)
  library(ggrepel)
  
  dt_filtro <- subset(dt, Istituto %in% nomi_istituti)
  
  dt_filtro %>%
    filter(Partito == par) %>%
    select(-Partito, -Campione) %>%
    pivot_wider(names_from = Istituto,
                values_from = Percentuale,
                values_fill = NA,
                values_fn = mean) %>%
    arrange(Data) -> dt_party
  
  dates <- tibble(Data = seq(min(dt$Data), max(dt$Data), "day"))
  dt_party <- dates %>% left_join(dt_party, by = "Data")
  
  dt_filtro %>%
    filter(Partito == par) %>%
    select(-Partito, -Percentuale) %>%
    pivot_wider(names_from = Istituto,
                values_from = Campione,
                values_fill = NA,
                values_fn = mean) %>%
    arrange(Data) -> dt_samples
  
  dt_samples <- dates %>% left_join(dt_samples, by = "Data")
  dt_samples[is.na(dt_samples)] <- min(dt_samples[, -1], na.rm = TRUE)
  
  Y <- as.matrix(dt_party[, -1])
  X <- as.matrix(dt_samples[, -1])
  p <- ncol(Y)
  n <- nrow(Y)
  
  mZ <- cbind(matrix(1, p, 1), diag(1, p))
  mZ <- mZ[, -ncol(mZ)]
  mZ[p, ] <- c(1, rep(-1, p - 1))
  mH <- array(0, c(p, p, n))
  
  mT <- diag(1, p)
  mQ <- matrix(NA_real_, 1, 1)
  mR <- rbind(matrix(1, 1, 1), matrix(0, p - 1, 1))
  
  va1 <- matrix(c(20, rep(0, p - 1)), p, 1)
  mP1 <- as.matrix(bdiag(matrix(56.25, 1, 1), diag(10, p - 1)))
  mP1inf <- matrix(0, p, p)
  
  s_names <- c("mu", paste0("delta_", 1:(p - 1)))
  
  mod <- SSModel(Y ~ 0 + SSMcustom(mZ, mT, mR, mQ, va1, mP1, mP1inf,
                                   state_names = s_names),
                 H = mH)
  
  updt <- function(pars, model, samples) {
    model$Q[1, 1, 1] <- exp(pars[1])
    var_eps <- exp(pars[2])
    for (t in 1:nrow(samples)) {
      diag(model$H[,,t]) <- var_eps / samples[t, ]
    }
    model
  }
  
  set.seed(123)
  fit <- fitSSM(model = mod,
                inits = log(c(var_eta = 0.1, var_eps = 2000)),
                updatefn = updt,
                update_args = list(samples = X))
  
  kfs <- KFS(fit$model, filtering = "state", smoothing = "state")
  
  dt_party_trend <- tibble(Data = dt_party$Data,
                           Trend = kfs$alphahat[, 1])
  
  g1 <- dt_filtro %>%
    filter(Partito == par) %>%
    ggplot(aes(x = Data, y = Percentuale)) +
    geom_point(color = co, alpha = 0.2) +
    geom_line(aes(x = Data, y = Trend), data = dt_party_trend, linewidth = 1) +
    ggtitle(paste("Intenzioni di voto per", par)) +
    theme_minimal(base_size = 13)
  
  # Analisi del bias
  delta_idx <- 2:p
  last_t <- nrow(kfs$alphahat)
  
  delta_hat <- kfs$alphahat[last_t, delta_idx]
  var_delta <- diag(kfs$V[delta_idx, delta_idx, last_t])
  se_delta <- sqrt(var_delta)
  
  z <- qnorm(0.975)
  ci_low <- delta_hat - z * se_delta
  ci_high <- delta_hat + z * se_delta
  
  bias_tbl <- tibble(
    Istituto = colnames(Y)[1:(p - 1)],
    Bias = delta_hat,
    Lower95 = ci_low,
    Upper95 = ci_high
  ) %>%
    arrange(desc(Bias))
  
  bias_ultimo <- -sum(delta_hat)
  var_ultimo <- sum(var_delta)
  se_ultimo <- sqrt(var_ultimo)
  
  bias_tbl <- bind_rows(
    bias_tbl,
    tibble(
      Istituto = colnames(Y)[p],
      Bias = bias_ultimo,
      Lower95 = bias_ultimo - z * se_ultimo,
      Upper95 = bias_ultimo + z * se_ultimo
    )
  ) %>%
    arrange(desc(Bias))
  
  g2 <- bias_tbl %>%
    ggplot(aes(x = reorder(Istituto, Bias), y = Bias)) +
    geom_point() +
    geom_errorbar(aes(ymin = Lower95, ymax = Upper95), width = .2) +
    coord_flip() +
    labs(x = "Istituto", y = "Bias (%)",
         title = "Bias stimato degli istituti (effetto 'house') con IC 95%") +
    theme_minimal(base_size = 13)
  
  # Confronto con bias reale (elezioni)
  elez <- as.data.frame(read_xlsx("Elezioni2022.xlsx"))
  elez[,1] <- c(unique(dt$Partito)[1], unique(dt$Partito)[5],
                unique(dt$Partito)[4], unique(dt$Partito)[3], unique(dt$Partito)[2])
  
  data_riferimento <- as.Date("2022-09-25")
  partiti_esclusi <- c("Az", "IV")
  
  df_preelez <- dt %>%
    filter(Data <= data_riferimento, !(Partito %in% partiti_esclusi)) %>%
    group_by(Partito, Istituto) %>%
    filter(Data == max(Data)) %>%
    ungroup() %>%
    select(Partito, Istituto, Data, Percentuale)
  
  bias_reale <- df_preelez %>%
    filter(Partito == par) %>%
    mutate(Bias = Percentuale - elez[elez$Partito == par, 2]) %>%
    select(Istituto, Bias)
  
  df_estrea <- bias_reale %>%
    rename(Bias_reale = Bias) %>%
    left_join(bias_tbl %>% select(Istituto, Bias_modello = Bias),
              by = "Istituto")
  
  g3 <- ggplot(df_estrea, aes(x = Bias_reale, y = Bias_modello, label = Istituto)) +
    geom_smooth(method = "lm", se = FALSE, color = co, 
                linetype = "dashed", linewidth = 0.6) +
    geom_label_repel(size = 3, label.padding = unit(0.15, "lines"), color = co) +
    labs(
      x = "Bias reale (sondaggio - risultato elettorale)",
      y = "Bias stimato dal modello",
      title = paste("Confronto Bias Reale vs Stimato -", par)
    ) +
    theme_minimal()
  
  return(list(
    grafico_trend = g1,
    grafico_bias_stimato = g2,
    grafico_confronto_reale_stimato = g3,
    bias_stimato = bias_tbl,
    trend_temporale = dt_party_trend
  ))
}
```

## Calcolo degli Intervalli di Confidenza sui Bias

Il bias sistematico $\delta_j$ è stimato come stato latente costante nel tempo. Gli intervalli di confidenza al 95% per ciascun $\delta_j$ derivano direttamente dalla matrice di varianza stimata dal filtro di Kalman all’ultimo tempo $T$:

$$
IC_{95\%}(\delta_j) = \left[\hat{\delta}_j \pm z_{0.975} \cdot \sqrt{\text{Var}(\hat{\delta}_j)}\right]
$$

Poiché il modello impone il vincolo di identificazione $\sum_j \delta_j = 0$, il bias dell’ultimo istituto viene ricavato per differenza:

$$
\delta_p = - \sum_{j=1}^{p-1} \delta_j
$$

Il suo errore standard si ottiene propagando l’incertezza dei primi $p-1$ termini:
$$
\text{Var}(\delta_p) = \sum_{j=1}^{p-1} \text{Var}(\delta_j)
$$

# Modello con Bias + Varianza Libera (bias_free_var_mod)
Combinazione dei due modelli precedenti:

$$
y_{j,t} = \mu_t + \delta_j + \varepsilon_{j,t}, \quad \varepsilon_{j,t} \sim \mathcal{N}\left(0, \frac{\sigma_j^2}{n_{j,t}}\right)
$$

Questo modello è il più flessibile: stima sia l’effetto *casa* (bias sistematico $\delta_j$) sia l’incertezza specifica di ciascun istituto ($\sigma_j^2$).

```{r}
bias_free_var_mod <- function(par, co) {
  library(tidyverse)
  library(KFAS)
  library(Matrix)
  library(readxl)
  library(lubridate)
  library(ggrepel)
  
  dt_filtro <- subset(dt, Istituto %in% nomi_istituti)
  
  # Dati per il partito
  dt_party <- dt_filtro %>%
    filter(Partito == par) %>%
    select(-Partito, -Campione) %>%
    pivot_wider(names_from = Istituto,
                values_from = Percentuale,
                values_fill = NA,
                values_fn = mean) %>%
    arrange(Data)
  
  dates <- tibble(Data = seq(min(dt$Data), max(dt$Data), by = "day"))
  dt_party <- dates %>% left_join(dt_party, by = "Data")
  
  dt_samples <- dt_filtro %>%
    filter(Partito == par) %>%
    select(-Partito, -Percentuale) %>%
    pivot_wider(names_from = Istituto,
                values_from = Campione,
                values_fill = NA,
                values_fn = mean) %>%
    arrange(Data)
  
  dt_samples <- dates %>% left_join(dt_samples, by = "Data")
  dt_samples[is.na(dt_samples)] <- min(dt_samples[, -1], na.rm = TRUE)
  
  Y <- as.matrix(dt_party[, -1])
  X <- as.matrix(dt_samples[, -1])
  p <- ncol(Y)
  n <- nrow(Y)
  
  mZ <- cbind(matrix(1, p, 1), diag(1, p))
  mZ <- mZ[, -ncol(mZ)]
  mZ[p, ] <- c(1, rep(-1, p - 1))
  mH <- array(0, c(p, p, n))
  mT <- diag(1, p)
  mQ <- matrix(NA_real_, 1, 1)
  mR <- rbind(matrix(1, 1, 1), matrix(0, p - 1, 1))
  
  va1 <- matrix(c(20, rep(0, p - 1)), p, 1)
  mP1 <- as.matrix(bdiag(matrix(56.25, 1, 1), diag(10, p - 1)))
  mP1inf <- matrix(0, p, p)
  
  s_names <- c("mu", paste0("delta_", 1:(p - 1)))
  mod <- SSModel(Y ~ 0 + SSMcustom(mZ, mT, mR, mQ, va1, mP1, mP1inf,
                                   state_names = s_names),
                 H = mH)
  
  updt <- function(pars, model, samples) {
    model$Q[1, 1, 1] <- exp(pars[1])
    var_eps <- exp(pars[-1])
    for (t in 1:nrow(samples)) {
      diag(model$H[,,t]) <- var_eps / samples[t, ]
    }
    model
  }
  
  fit <- fitSSM(model       = mod,
                inits       = log(c(var_eta = 0.1, var_eps = rep(2000, p))),
                updatefn    = updt,
                update_args = list(samples = X),
                hessian     = TRUE,
                method      = "BFGS")
  
  kfs   <- KFS(fit$model, filtering = "state", smoothing = "state")
  trend <- tibble(Data = dt_party$Data, Trend = kfs$alphahat[, 1])
  
  # GRAFICO TREND
  g1 <- dt_filtro %>%
    filter(Partito == par) %>%
    ggplot(aes(x = Data, y = Percentuale)) +
    geom_point(color = co, alpha = 0.2) +
    geom_line(data = trend, aes(x = Data, y = Trend), linewidth = 1) +
    ggtitle(paste("Intenzioni di voto per", par)) +
    theme_minimal(base_size = 13)
  
  # VARIANZE
  param_estimates <- fit$optim.out$par
  vcov_matrix     <- solve(fit$optim.out$hessian)
  std_errors      <- sqrt(diag(vcov_matrix))
  z               <- qnorm(0.975)
  
  ci_lower <- exp(param_estimates - z * std_errors)[-1]
  ci_upper <- exp(param_estimates + z * std_errors)[-1]
  
  var_tbl <- data.frame(
    Istituto = colnames(Y),
    Varianza = exp(param_estimates[-1]),
    Lower95  = ci_lower,
    Upper95  = ci_upper
  )
  
  g2 <- var_tbl %>%
    mutate(Istituto = fct_reorder(Istituto, Varianza)) %>%
    ggplot(aes(x = Istituto, y = Varianza)) +
    geom_point(size = 2) +
    geom_errorbar(aes(ymin = Lower95, ymax = Upper95), width = .25) +
    coord_flip() +
    labs(title = "Varianze specifiche degli istituti – IC95%",
         x = "Istituto", y = expression(hat(sigma)^2)) +
    theme_minimal(base_size = 13)
  
  # BIAS
  delta_idx <- 2:p
  last_t    <- nrow(kfs$alphahat)
  delta_hat <- kfs$alphahat[last_t, delta_idx]
  var_delta <- diag(kfs$V[delta_idx, delta_idx, last_t])
  se_delta  <- sqrt(var_delta)
  
  ci_low  <- delta_hat - z * se_delta
  ci_high <- delta_hat + z * se_delta
  
  bias_tbl <- tibble(
    Istituto = colnames(Y)[1:(p - 1)],
    Bias     = delta_hat,
    Lower95  = ci_low,
    Upper95  = ci_high
  ) %>% arrange(desc(Bias))
  
  bias_ultimo <- -sum(delta_hat)
  se_ultimo   <- sqrt(sum(var_delta))
  
  bias_tbl <- bind_rows(
    bias_tbl,
    tibble(
      Istituto = colnames(Y)[p],
      Bias     = bias_ultimo,
      Lower95  = bias_ultimo - z * se_ultimo,
      Upper95  = bias_ultimo + z * se_ultimo
    )
  ) %>% arrange(desc(Bias))
  
  g3 <- bias_tbl %>%
    ggplot(aes(x = reorder(Istituto, Bias), y = Bias)) +
    geom_point() +
    geom_errorbar(aes(ymin = Lower95, ymax = Upper95), width = .2) +
    coord_flip() +
    labs(x = "Istituto", y = "Bias (%)",
         title = "Bias stimato degli istituti (effetto 'house') con IC 95%") +
    theme_minimal()
  
  # Confronto con bias reale
  elez <- as.data.frame(read_xlsx("Elezioni2022.xlsx"))
  elez[, 1] <- c(unique(dt$Partito)[1], unique(dt$Partito)[5],
                 unique(dt$Partito)[4], unique(dt$Partito)[3],
                 unique(dt$Partito)[2])
  
  data_rif <- as.Date("2022-09-25")
  partiti_esclusi <- c("Az", "IV")
  
  df_preelez <- dt %>%
    filter(Data <= data_rif, !(Partito %in% partiti_esclusi)) %>%
    group_by(Partito, Istituto) %>%
    filter(Data == max(Data)) %>%
    ungroup() %>%
    select(Partito, Istituto, Percentuale)
  
  bias_reale <- df_preelez %>%
    filter(Partito == par) %>%
    mutate(Bias = Percentuale - elez[elez$Partito == par, 2]) %>%
    select(Istituto, Bias)
  
  df_estrea <- bias_reale %>%
    rename(Bias_reale   = Bias) %>%
    left_join(bias_tbl %>% select(Istituto, Bias_modello = Bias),
              by = "Istituto")
  
  g4 <- ggplot(df_estrea, aes(x = Bias_reale, y = Bias_modello, label = Istituto)) +
    geom_smooth(method = "lm", se = FALSE, color = co, linetype = "dashed", linewidth = 0.6) +
    geom_label_repel(size = 3, label.padding = unit(0.15, "lines"), color = co) +
    labs(x = "Bias reale (sondaggio - risultato elettorale)",
         y = "Bias stimato dal modello",
         title = paste("Confronto Bias Reale vs Stimato -", par)) +
    theme_minimal()
  
  # SCOMPOSIZIONE MSE (come da tuo snippet)
  ci <- var_tbl %>%
    rename(Istituto = Istituto,
           Varianza_mod = Varianza)
  
  var_eps_vec <- exp(fit$optim.out$par[-1])
  names(var_eps_vec) <- colnames(Y)  
  
  dt_cmse <- dt[dt$Partito == par, ]
  dt_cmse$Campione[is.na(dt_cmse$Campione)] <- min(dt_cmse$Campione, na.rm = TRUE)
  avg_camp <- tapply(dt_cmse$Campione, dt_cmse$Istituto, mean)
  avg_camp <- avg_camp[colnames(Y)]
  
  var_media <- tibble(Istituto = colnames(Y), Var_media = var_eps_vec / avg_camp)
  
  mse_tbl <- bias_tbl %>%
    select(Istituto, Bias) %>%
    left_join(var_media, by = "Istituto") %>%
    mutate(
      MSE      = Bias^2 + Var_media,
      PropBias = (Bias^2) / MSE,
      PropVar  = Var_media / MSE
    )
  
  mse_tbl <- mse_tbl %>%
    mutate(
      Bias2    = Bias^2,
      Varianza = Var_media
    ) %>%
    select(Istituto, Bias2, Varianza) %>%
    pivot_longer(-Istituto,
                 names_to  = "Componente",
                 values_to = "Valore")
  
  # Grafico a barre impilate
  g5 <- ggplot(mse_tbl, aes(x = reorder(Istituto, Valore), 
                            y = Valore, 
                            fill = Componente)) +
    geom_col() +
    coord_flip() +
    labs(
      title = paste("Composizione dell'MSE per istituto –", par),
      x     = "Istituto",
      y     = "MSE",
      fill  = ""
    )
  
  list(
    trend             = g1,
    varianze          = g2,
    bias_stimato      = g3,
    bias_vs_reale     = g4,
    mse_decomposition = g5,
    tabella_varianze  = var_tbl,
    tabella_bias      = bias_tbl,
    trend_dati        = trend
  )
}
```

## Scomposizione dell'errore quadratico medio
Per ogni istituto stimiamo:

$$
\text{MSE} = \text{Bias}^2 + \text{Varianza}
$$

Questo ci permette di capire se l’errore è più dovuto a bias sistematico o a rumore statistico.


# Modello Binomiale (bin_mod)
In questo modello, i dati sono trattati come conteggi binomiali:

$$
y_{j,t} \sim \text{Binomiale}(n_{j,t}, \pi_t), \quad \text{con} \quad \text{logit}(\pi_t) = \mu_t
$$

Questo approccio permette di stimare una media a posteriori del supporto elettorale sulla scala della probabilità, incorporando direttamente l’informazione campionaria.
```{r}
bin_mod <- function(par,co) {
  library(tidyverse)
  library(KFAS)
  
  # Dati filtrati
  dt_filtro <- subset(dt, Istituto %in% nomi_istituti)
  
  dt_filtro %>%
    filter(Partito == par) %>%
    select(-Partito, -Campione) %>%
    pivot_wider(names_from = Istituto,
                values_from = Percentuale,
                values_fill = NA,
                values_fn = mean) %>%
    arrange(Data) -> dt_party
  
  dates <- tibble(Data = seq(min(dt$Data), max(dt$Data), "day"))
  dt_party <- dates %>% left_join(dt_party, by = "Data")
  
  dt_filtro %>%
    filter(Partito == par) %>%
    select(-Partito, -Percentuale) %>%
    pivot_wider(names_from = Istituto,
                values_from = Campione,
                values_fill = NA,
                values_fn = mean) %>%
    arrange(Data) -> dt_samples
  
  dt_samples <- dates %>% left_join(dt_samples, by = "Data")
  dt_samples[is.na(dt_samples)] <- min(dt_samples[, -1], na.rm = TRUE)
  
  # Preparazione dati per il modello binomiale
  Y_pct <- as.matrix(dt_party[, -1]) / 100
  U_trials <- as.matrix(round(dt_samples[, -1]))
  Y <- round(Y_pct * U_trials)
  
  p <- length(unique(dt_filtro$Istituto))
  n <- nrow(dt_party)
  
  # Matrici per SSModel
  mZ <- matrix(1, p, 1)
  mT <- matrix(1)
  mQ <- matrix(NA_real_, 1, 1)
  mR <- matrix(1)
  va1 <- matrix(-1.4)
  mP1 <- matrix(0.3)
  mP1inf <- matrix(0)
  
  mod <- SSModel(Y ~ 0 + SSMcustom(Z = mZ, T = mT, R = mR, Q = mQ, 
                                   a1 = va1, P1 = mP1, P1inf = mP1inf,
                                   state_names = "mu"),
                 distribution = "binomial", u = U_trials)
  
  updt <- function(pars, model) {
    model$Q[1, 1, 1] <- exp(pars[1])
    model
  }
  
  fit <- fitSSM(model = mod,
                inits = log(0.001),
                updatefn = updt,
                method = 'BFGS')
  
  kfs <- KFS(fit$model, smoothing = "mean")
  
  # Trend stimato (media a posteriori)
  dt_party_trend <- tibble(Data = dt_party$Data,
                           Trend = kfs$muhat[, 1] * 100)
  
  g1 <- dt_filtro %>%
    filter(Partito == par) %>%
    ggplot(aes(x = Data, y = Percentuale)) +
    geom_point(color = co, alpha = 0.2) +
    geom_line(data = dt_party_trend, aes(x = Data, y = Trend), linewidth = 1) +
    ggtitle(paste("Intenzioni di voto per", par)) +
    theme_minimal(base_size = 13)
  
  # Importance sampling
  imp <- importanceSSM(fit$model, type = "state", antithetics = TRUE)
  w <- imp$weights / sum(imp$weights)
  
  mean_imp <- low_imp <- up_imp <- numeric()
  
  for (i in 1:nrow(Y_pct)) {
    ilogit_imp <- plogis(imp$samples[i, 1, ])
    mean_imp[i] <- sum(ilogit_imp * w)
    oo <- order(ilogit_imp)
    low_imp[i] <- ilogit_imp[oo][which.min(abs(cumsum(w[oo]) - 0.025))]
    up_imp[i]  <- ilogit_imp[oo][which.min(abs(cumsum(w[oo]) - 0.975))]
  }
  
  res <- tibble(
    Data = dt_party$Data,
    mean = mean_imp * 100,
    low  = low_imp * 100,
    high = up_imp * 100
  )
  
  g2 <- ggplot(res, aes(x = Data, y = mean)) +
    geom_ribbon(aes(ymin = low, ymax = high), fill = co, alpha = 0.25) +
    geom_line(size = 1, colour = co) +
    labs(title    = paste("Quota stimata della", par, "nel tempo"),
         subtitle = "Modello a stati binomiale – stima smoothata con importance sampling",
         y        = "(%)",
         x        = NULL,
         caption  = "Banda = intervallo di credibilità al 95%") +
    theme_minimal(base_size = 13) +
    theme(plot.title.position = "plot",
          plot.caption.position = "plot")
  
  list(
    grafico_trend_lineare = g1,
    grafico_importance_ci = g2,
    stime_credibilita = res
  )
}
```

## Perché usare Importance Sampling?

Nel modello binomiale, le osservazioni $y_{j,t}$ seguono una distribuzione discreta con link logit:

$$
y_{j,t} \sim \text{Binom}(n_{j,t}, \pi_t), \quad \text{logit}(\pi_t) = \mu_t
$$

La distribuzione a posteriori di $\mu_t$ (e quindi di $\pi_t$) non ha forma chiusa. Per ottenere stime puntuali e intervalli di credibilità per $\pi_t$, ricorriamo all’importance sampling sui campioni latenti di $\mu_t$.

Il metodo consente di approssimare:

- $\mathbb{E}[\pi_t \mid \text{dati}]$
- Intervalli credibili al 95% (quantili pesati)

A partire da:

$$
\hat{\pi}_t = \sum_{s=1}^{S} \text{logit}^{-1}(\mu_t^{(s)}) \cdot w_s
$$

Dove $\mu_t^{(s)}$ sono i campioni latenti e $w_s$ i pesi normalizzati. Questo approccio è particolarmente utile in modelli non lineari e non gaussiani come il binomiale, dove l’inferenza esatta è intrattabile.

# Modello Binomiale con Bias (bin_bias_mod)
In questo modello, ogni istituto ha una propria deviazione sistematica $\delta_j$ rispetto al trend comune $\mu_t$:

$$
y_{j,t} \sim \text{Binomiale}(n_{j,t}, \pi_{j,t}), \quad \text{logit}(\pi_{j,t}) = \mu_t + \delta_j
$$

Con vincolo di identificazione:

$$
\sum_j \delta_j = 0
$$

Questo modello consente di stimare il supporto elettorale corretto a posteriori tenendo conto sia della variabilità campionaria sia del bias sistematico dell’istituto.

```{r}
bin_bias_mod <- function(party,co) {
  library(tidyverse)
  library(Matrix)
  library(KFAS)
  library(readxl)
  library(ggrepel)
  library(lubridate)
  
  # --- Caricamento e preprocessing
  dt <- read.csv2("Sondaggi_2024-04-30.csv")
  dt$Percentuale <- as.numeric(dt$Percentuale)
  dt$Data <- as.Date(dt$Data, format = "%d/%m/%Y")
  nomi_istituti <- names(sort(table(dt$Istituto), decreasing = TRUE)[1:16])
  dt <- subset(dt, Istituto %in% nomi_istituti)
  
  # --- Dati wide per partito
  dt_party <- dt %>%
    filter(Partito == party) %>%
    select(-Partito, -Campione) %>%
    pivot_wider(names_from = Istituto, values_from = Percentuale,
                values_fill = NA, values_fn = mean) %>%
    arrange(Data)
  
  dates <- tibble(Data = seq(min(dt$Data), max(dt$Data), "day"))
  dt_party <- left_join(dates, dt_party, by = "Data")
  
  dt_samples <- dt %>%
    filter(Partito == party) %>%
    select(-Partito, -Percentuale) %>%
    pivot_wider(names_from = Istituto, values_from = Campione,
                values_fill = NA, values_fn = mean) %>%
    arrange(Data)
  dt_samples <- left_join(dates, dt_samples, by = "Data")
  dt_samples[is.na(dt_samples)] <- min(dt_samples[, -1], na.rm = TRUE)
  
  # --- Modello binomiale a stati
  Y_pct <- as.matrix(dt_party[, -1]) / 100
  U_trials <- as.matrix(round(dt_samples[, -1]))
  Y <- round(Y_pct * U_trials)
  p <- ncol(Y)
  
  mZ <- rbind(cbind(1, diag(p - 1)), c(1, rep(-1, p - 1)))
  mT <- diag(p)
  mR <- rbind(1, matrix(0, p - 1, 1))
  mQ <- matrix(NA_real_, 1, 1)
  va1 <- matrix(c(-1.3, rep(0, p - 1)), p, 1)
  mP1 <- as.matrix(bdiag(1, diag(10, p - 1)))
  mP1inf <- matrix(0, p, p)
  s_names <- c("mu", paste0("delta_", 1:(p - 1)))
  
  mod <- SSModel(Y ~ -1 + SSMcustom(Z = mZ, T = mT, R = mR, Q = mQ,
                                    a1 = va1, P1 = mP1, P1inf = mP1inf,
                                    state_names = s_names),
                 distribution = "binomial", u = U_trials)
  
  fit <- fitSSM(mod, inits = log(0.05), updatefn = \(pars, model) {
    model$Q[1, 1, 1] <- exp(pars[1]); model
  }, method = "BFGS")
  
  kfs <- KFS(fit$model, smoothing = c("state", "signal", "mean"))
  
  # --- Importance sampling
  imp <- importanceSSM(fit$model, type = "state", antithetics = TRUE)
  w <- imp$weights / sum(imp$weights)
  
  extract_ci <- function(i) {
    ilogit <- plogis(imp$samples[i, 1, ])
    oo <- order(ilogit)
    c(
      mean = sum(ilogit * w),
      low  = ilogit[oo][which.min(abs(cumsum(w[oo]) - 0.025))],
      high = ilogit[oo][which.min(abs(cumsum(w[oo]) - 0.975))]
    )
  }
  
  ci_list <- t(sapply(1:nrow(Y_pct), extract_ci))
  trend_df <- data.frame(
    Data = dt_party$Data,
    mean = ci_list[, "mean"] * 100,
    low  = ci_list[, "low"]  * 100,
    high = ci_list[, "high"] * 100
  )
  
  # --- Grafico trend
  g_trend <- ggplot(trend_df, aes(x = Data, y = mean)) +
    geom_ribbon(aes(ymin = low, ymax = high), fill = co, alpha = 0.25) +
    geom_line(size = 1, colour = co) +
    labs(
      title = paste("Quota stimata di", party, "nel tempo"),
      subtitle = "Modello a stati binomiale – stima smoothata con importance sampling",
      y = "(%)", x = NULL,
      caption = "Banda = intervallo di credibilità al 95%"
    ) +
    theme_minimal(base_size = 13) +
    theme(plot.title.position = "plot", plot.caption.position = "plot")
  
  # --- Bias stimati
  wquant <- function(x, w, probs = c(0.025, 0.975)) {
    oo <- order(x); x <- x[oo]; w <- w[oo] / sum(w); cw <- cumsum(w)
    sapply(probs, function(p) x[which.min(abs(cw - p))])
  }
  
  pi_ref <- mean(plogis(kfs$alphahat[, 1]))
  delta_samples <- imp$samples[1, 2:p, ]
  delta_samples <- rbind(delta_samples, -colSums(delta_samples))
  nomi_istituti <- colnames(Y)
  
  bias_df <- map_dfr(1:p, function(j) {
    d <- delta_samples[j, ]
    m <- sum(d * w)
    ci <- wquant(d, w)
    
    bias_pp <- 100 * (plogis(qlogis(pi_ref) + m) - pi_ref)
    low_pp  <- 100 * (plogis(qlogis(pi_ref) + ci[1]) - pi_ref)
    high_pp <- 100 * (plogis(qlogis(pi_ref) + ci[2]) - pi_ref)
    
    tibble(
      Istituto   = nomi_istituti[j],
      Bias_pp    = bias_pp,
      Low_95_pp  = low_pp,
      High_95_pp = high_pp
    )
  }) %>% arrange(desc(Bias_pp))
  
  g_bias <- bias_df %>%
    mutate(Istituto = fct_reorder(Istituto, Bias_pp)) %>%
    ggplot(aes(x = Istituto, y = Bias_pp)) +
    geom_hline(yintercept = 0, colour = "grey60", linewidth = .3) +
    geom_point(size = 2) +
    geom_errorbar(aes(ymin = Low_95_pp, ymax = High_95_pp),
                  width = .25, linewidth = .6) +
    coord_flip() +
    labs(
      title = paste("Bias stimato degli istituti –", party),
      subtitle = "Effetto-casa (δ) con intervallo di credibilità al 95 %",
      x = NULL, y = "Bias (%)"
    ) +
    theme_minimal(base_size = 13) +
    theme(plot.title.position = "plot")
  
  # --- Confronto con bias reale (elezioni)
  elez <- as.data.frame(read_xlsx("Elezioni2022.xlsx"))
  elez[, 1] <- c(unique(dt$Partito)[1], unique(dt$Partito)[5],
                 unique(dt$Partito)[4], unique(dt$Partito)[3],
                 unique(dt$Partito)[2])
  
  data_rif <- as.Date("2022-09-25")
  partiti_esclusi <- c("Az", "IV")
  
  df_preelez <- dt %>%
    filter(Data <= data_rif, !(Partito %in% partiti_esclusi)) %>%
    group_by(Partito, Istituto) %>%
    filter(Data == max(Data)) %>%
    ungroup() %>%
    select(Partito, Istituto, Data, Percentuale)
  
  bias_reale <- df_preelez %>%
    filter(Partito == party) %>%
    mutate(Bias = Percentuale - elez[elez$Partito == party, 2]) %>%
    select(Istituto, Bias)
  
  df_confronto <- bias_reale %>%
    rename(Bias_reale = Bias) %>%
    left_join(bias_df %>% select(Istituto, Bias_modello = Bias_pp),
              by = "Istituto")
  
  g_confronto <- ggplot(df_confronto, aes(Bias_reale, Bias_modello, label = Istituto)) +
    geom_abline(slope = 1, intercept = 0, colour = "grey60", linewidth = .4) +
    geom_smooth(method = "lm", se = FALSE, colour = co,
                linetype = "dashed", linewidth = .7) +
    geom_point(size = 2, colour = co) +
    geom_label_repel(size = 3, label.padding = unit(0.15, "lines"),
                     colour = co, max.overlaps = Inf) +
    labs(
      title = paste("Confronto bias reale vs stimato –", party),
      subtitle = "Ultimo sondaggio prima del voto (25 set 2022) vs house-effect",
      x = "Bias reale (p.p.)", y = "Bias modello (p.p.)"
    ) +
    theme_minimal(base_size = 13) +
    theme(plot.title.position = "plot")
  
  # --- OUTPUT finale ---
  return(list(
    grafico_trend     = g_trend,
    grafico_bias      = g_bias,
    grafico_confronto = g_confronto,
    trend_stimato     = trend_df,
    bias_stimati      = bias_df
  ))
}
```

# Esempio Interattivo

Seleziona un partito da analizzare per confrontare:

- l’evoluzione stimata del consenso nel tempo,
- la variabilità tra istituti,
- il bias sistematico (effetto "house"),
- la decomposizione dell’errore (MSE),
- e il confronto tra bias reale (rispetto alle elezioni) e bias stimato.

```{r setup_interactive, include=FALSE}
modelli_calcolati <- readRDS("modelli_precotti.rds")
partiti <- names(modelli_calcolati)
```

```{r ui_party_input}
inputPanel(
  selectInput("selected_party", "Seleziona Partito:", 
              choices = partiti, selected = "Lega")
)
```

## Modello con Varianza Libera
```{r}
output$freevar_plot1 <- renderPlot({
  modelli_calcolati[[input$selected_party]]$freevar$grafico_trend
})
plotOutput("freevar_plot1")
```

```{r}
output$freevar_plot2 <- renderPlot({
  modelli_calcolati[[input$selected_party]]$freevar$grafico_varianze
})
plotOutput("freevar_plot2")
```

## Modello con Bias Fisso
```{r}
output$bias_plot1 <- renderPlot({
  modelli_calcolati[[input$selected_party]]$bias$grafico_trend
})
plotOutput("bias_plot1")
```

```{r}
output$bias_plot2 <- renderPlot({
  modelli_calcolati[[input$selected_party]]$bias$grafico_bias_stimato
})
plotOutput("bias_plot2")
```

```{r}
output$bias_plot3 <- renderPlot({
  modelli_calcolati[[input$selected_party]]$bias$grafico_confronto_reale_stimato
})
plotOutput("bias_plot3")
```

## Modello con Bias + Varianza Libera
```{r}
output$bfv_plot1 <- renderPlot({
  modelli_calcolati[[input$selected_party]]$bfv$trend
})
plotOutput("bfv_plot1")
```

```{r}
output$bfv_plot2 <- renderPlot({
  modelli_calcolati[[input$selected_party]]$bfv$varianze
})
plotOutput("bfv_plot2")
```

```{r}
output$bfv_plot3 <- renderPlot({
  modelli_calcolati[[input$selected_party]]$bfv$bias_stimato
})
plotOutput("bfv_plot3")
```

```{r}
output$bfv_plot4 <- renderPlot({
  modelli_calcolati[[input$selected_party]]$bfv$bias_vs_reale
})
plotOutput("bfv_plot4")
```

```{r}
output$bfv_plot5 <- renderPlot({
  modelli_calcolati[[input$selected_party]]$bfv$mse_decomposition
})
plotOutput("bfv_plot5")
```

## Modello Binomiale
```{r}
output$bin_plot1 <- renderPlot({
  modelli_calcolati[[input$selected_party]]$bin$grafico_trend_lineare
})
plotOutput("bin_plot1")
```

```{r}
output$bin_plot2 <- renderPlot({
  modelli_calcolati[[input$selected_party]]$bin$grafico_importance_ci
})
plotOutput("bin_plot2")
```

## Modello Binomiale con Bias
```{r}
output$binbias_plot1 <- renderPlot({
  modelli_calcolati[[input$selected_party]]$binbias$grafico_trend
})
plotOutput("binbias_plot1")
```

```{r}
output$binbias_plot2 <- renderPlot({
  modelli_calcolati[[input$selected_party]]$binbias$grafico_bias
})
plotOutput("binbias_plot2")
```

```{r}
output$binbias_plot3 <- renderPlot({
  modelli_calcolati[[input$selected_party]]$binbias$grafico_confronto
})
plotOutput("binbias_plot3")
```


